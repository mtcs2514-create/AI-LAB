{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "l5a799cIc2w_",
        "outputId": "4a613150-3245-4f8c-a712-71fe61376f4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Downloading dataset...\n",
            " Unzipping dataset...\n",
            " Loaded 1400 reviews.\n",
            "\n",
            "=====  Naive Bayes =====\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.78      0.89      0.83       140\n",
            "         pos       0.87      0.76      0.81       140\n",
            "\n",
            "    accuracy                           0.82       280\n",
            "   macro avg       0.83      0.82      0.82       280\n",
            "weighted avg       0.83      0.82      0.82       280\n",
            "\n",
            "\n",
            "=====  Logistic Regression (MaxEnt) =====\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.81      0.84      0.82       140\n",
            "         pos       0.83      0.81      0.82       140\n",
            "\n",
            "    accuracy                           0.82       280\n",
            "   macro avg       0.82      0.82      0.82       280\n",
            "weighted avg       0.82      0.82      0.82       280\n",
            "\n",
            "\n",
            "=====  Support Vector Machine =====\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.85      0.88      0.87       140\n",
            "         pos       0.88      0.85      0.86       140\n",
            "\n",
            "    accuracy                           0.86       280\n",
            "   macro avg       0.86      0.86      0.86       280\n",
            "weighted avg       0.86      0.86      0.86       280\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#  Install dependencies\n",
        "%pip install -q scikit-learn pandas\n",
        "\n",
        "import os\n",
        "import re\n",
        "import zipfile\n",
        "import urllib.request\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# === Step 1: Download and unzip dataset ===\n",
        "url = \"http://www.cs.cornell.edu/people/pabo/movie-review-data/mix20_rand700_tokens_cleaned.zip\"\n",
        "zip_path = \"mix20_rand700_tokens_cleaned.zip\"\n",
        "data_folder = \"mix20_rand700_tokens_cleaned\"\n",
        "\n",
        "if not os.path.exists(zip_path):\n",
        "    print(\" Downloading dataset...\")\n",
        "    urllib.request.urlretrieve(url, zip_path)\n",
        "\n",
        "if not os.path.exists(data_folder):\n",
        "    print(\" Unzipping dataset...\")\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(data_folder)\n",
        "\n",
        "# === Step 2: Load reviews and assign labels ===\n",
        "texts, labels = [], []\n",
        "\n",
        "# Define the paths to the positive and negative directories within 'tokens'\n",
        "pos_dir = os.path.join(data_folder, 'tokens', 'pos')\n",
        "neg_dir = os.path.join(data_folder, 'tokens', 'neg')\n",
        "\n",
        "# Load positive reviews\n",
        "if os.path.exists(pos_dir):\n",
        "    for fname in os.listdir(pos_dir):\n",
        "        if fname.endswith('.txt'): # Assuming the review files are .txt\n",
        "            with open(os.path.join(pos_dir, fname), 'r', encoding='utf-8', errors='ignore') as f:\n",
        "                texts.append(f.read())\n",
        "                labels.append('pos')\n",
        "else:\n",
        "    print(f\"Warning: Positive reviews directory not found at {pos_dir}\")\n",
        "\n",
        "# Load negative reviews\n",
        "if os.path.exists(neg_dir):\n",
        "    for fname in os.listdir(neg_dir):\n",
        "        if fname.endswith('.txt'): # Assuming the review files are .txt\n",
        "            with open(os.path.join(neg_dir, fname), 'r', encoding='utf-8', errors='ignore') as f:\n",
        "                texts.append(f.read())\n",
        "                labels.append('neg')\n",
        "else:\n",
        "     print(f\"Warning: Negative reviews directory not found at {neg_dir}\")\n",
        "\n",
        "print(f\" Loaded {len(texts)} reviews.\")\n",
        "\n",
        "\n",
        "# === Step 3: Train/test split ===\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    texts, labels, test_size=0.2, random_state=42, stratify=labels\n",
        ")\n",
        "\n",
        "# === Step 4: Define models ===\n",
        "models = {\n",
        "    \"Naive Bayes\": Pipeline([\n",
        "        ('tfidf', TfidfVectorizer()),\n",
        "        ('clf', MultinomialNB()),\n",
        "    ]),\n",
        "    \"Logistic Regression (MaxEnt)\": Pipeline([\n",
        "        ('tfidf', TfidfVectorizer()),\n",
        "        ('clf', LogisticRegression(max_iter=1000)),\n",
        "    ]),\n",
        "    \"Support Vector Machine\": Pipeline([\n",
        "        ('tfidf', TfidfVectorizer()),\n",
        "        ('clf', LinearSVC()),\n",
        "    ])\n",
        "}\n",
        "\n",
        "# === Step 5: Train and evaluate ===\n",
        "for name, model in models.items():\n",
        "    print(f\"\\n=====  {name} =====\")\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(classification_report(y_test, y_pred, target_names=[\"neg\", \"pos\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cr_0XxPNc8Aj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "wlQu8woNR0nl",
        "outputId": "8baac332-23ac-45ac-8aa1-8a112d9c0822"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=====  Naive Bayes =====\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'X_train' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-355984393.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n=====  {name} =====\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"neg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pos\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Modify TfidfVectorizer to include n-grams (unigrams and bigrams)\n",
        "models = {\n",
        "    \"Naive Bayes\": Pipeline([\n",
        "        ('tfidf', TfidfVectorizer(ngram_range=(1, 2))),\n",
        "        ('clf', MultinomialNB()),\n",
        "    ]),\n",
        "    \"Logistic Regression (MaxEnt)\": Pipeline([\n",
        "        ('tfidf', TfidfVectorizer(ngram_range=(1, 2))),\n",
        "        ('clf', LogisticRegression(max_iter=1000)),\n",
        "    ]),\n",
        "    \"Support Vector Machine\": Pipeline([\n",
        "        ('tfidf', TfidfVectorizer(ngram_range=(1, 2))),\n",
        "        ('clf', LinearSVC()),\n",
        "    ])\n",
        "}\n",
        "\n",
        "# Train and evaluate models with n-grams\n",
        "for name, model in models.items():\n",
        "    print(f\"\\n=====  {name} =====\")\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(classification_report(y_test, y_pred, target_names=[\"neg\", \"pos\"]))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}