{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58f0a939",
        "outputId": "8d548cdd-ad46-4c13-88f0-c3973d1adb80"
      },
      "source": [
        "import requests\n",
        "import tarfile\n",
        "import os\n",
        "\n",
        "url = \"http://www.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/news20.tar.gz\"\n",
        "output_path = \"/content/news20.tar.gz\"\n",
        "extract_path = \"/content/20_newsgroups\"\n",
        "\n",
        "\n",
        "print(f\"Downloading {url}...\")\n",
        "try:\n",
        "    response = requests.get(url, stream=True)\n",
        "    response.raise_for_status()\n",
        "    with open(output_path, 'wb') as f:\n",
        "        for chunk in response.iter_content(chunk_size=8192):\n",
        "            f.write(chunk)\n",
        "    print(\"Download complete.\")\n",
        "\n",
        "\n",
        "    print(f\"Extracting {output_path} to {extract_path}...\")\n",
        "    with tarfile.open(output_path, 'r:gz') as tar:\n",
        "        tar.extractall(path=extract_path)\n",
        "    print(\"Extraction complete.\")\n",
        "\n",
        "\n",
        "    print(\"\\nExtracted directories:\")\n",
        "    print(os.listdir(extract_path))\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error during download: {e}\")\n",
        "except tarfile.TarError as e:\n",
        "    print(f\"Error during extraction: {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred: {e}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://www.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/news20.tar.gz...\n",
            "Download complete.\n",
            "Extracting /content/news20.tar.gz to /content/20_newsgroups...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1006043854.py:22: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
            "  tar.extractall(path=extract_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extraction complete.\n",
            "\n",
            "Extracted directories:\n",
            "['20_newsgroup']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9dd58cf",
        "outputId": "0e508d72-dfd2-435b-f6c4-0961f59a60a0"
      },
      "source": [
        "import os\n",
        "\n",
        "data_dir = \"/content/20_newsgroups\"\n",
        "newsgroups = []\n",
        "texts = []\n",
        "\n",
        "for category in os.listdir(data_dir):\n",
        "    category_path = os.path.join(data_dir, category)\n",
        "    if os.path.isdir(category_path):\n",
        "        for filename in os.listdir(category_path):\n",
        "            file_path = os.path.join(category_path, filename)\n",
        "            if os.path.isfile(file_path):\n",
        "                with open(file_path, 'r', errors='ignore') as f:\n",
        "                    texts.append(f.read())\n",
        "                    newsgroups.append(category)\n",
        "\n",
        "print(f\"Loaded {len(texts)} documents.\")\n",
        "print(f\"Number of newsgroup categories: {len(set(newsgroups))}\")\n",
        "print(\"First 10 newsgroups:\", newsgroups[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 0 documents.\n",
            "Number of newsgroup categories: 0\n",
            "First 10 newsgroups: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f442d3eb",
        "outputId": "8fa39203-131a-4248-cfdb-30e9047c1baa"
      },
      "source": [
        "print(os.listdir(\"/content/20_newsgroups\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['20_newsgroup']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4c25d028",
        "outputId": "e5aa7519-7ae9-4754-a261-001c97fe60fe"
      },
      "source": [
        "data_dir = \"/content/20_newsgroups/20_newsgroup\"\n",
        "newsgroups = []\n",
        "texts = []\n",
        "\n",
        "for category in os.listdir(data_dir):\n",
        "    category_path = os.path.join(data_dir, category)\n",
        "    if os.path.isdir(category_path):\n",
        "        for filename in os.listdir(category_path):\n",
        "            file_path = os.path.join(category_path, filename)\n",
        "            if os.path.isfile(file_path):\n",
        "                with open(file_path, 'r', errors='ignore') as f:\n",
        "                    texts.append(f.read())\n",
        "                    newsgroups.append(category)\n",
        "\n",
        "print(f\"Loaded {len(texts)} documents.\")\n",
        "print(f\"Number of newsgroup categories: {len(set(newsgroups))}\")\n",
        "print(\"First 10 newsgroups:\", newsgroups[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 19997 documents.\n",
            "Number of newsgroup categories: 20\n",
            "First 10 newsgroups: ['comp.graphics', 'comp.graphics', 'comp.graphics', 'comp.graphics', 'comp.graphics', 'comp.graphics', 'comp.graphics', 'comp.graphics', 'comp.graphics', 'comp.graphics']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0608bd44",
        "outputId": "97e337c2-9032-4588-ceb5-4b35a85637d1"
      },
      "source": [
        "unique_newsgroups = list(set(newsgroups))\n",
        "print(\"Unique newsgroup categories:\", unique_newsgroups)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique newsgroup categories: ['rec.autos', 'talk.religion.misc', 'talk.politics.misc', 'comp.sys.mac.hardware', 'sci.crypt', 'talk.politics.guns', 'alt.atheism', 'sci.med', 'talk.politics.mideast', 'misc.forsale', 'comp.sys.ibm.pc.hardware', 'comp.windows.x', 'soc.religion.christian', 'sci.electronics', 'comp.os.ms-windows.misc', 'rec.sport.baseball', 'comp.graphics', 'sci.space', 'rec.sport.hockey', 'rec.motorcycles']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f13ba055",
        "outputId": "9ec79721-225d-4cbf-fc43-2c273178e42e"
      },
      "source": [
        "newsgroup_1 = 'sci.space'\n",
        "newsgroup_2 = 'rec.autos'\n",
        "\n",
        "texts_two_newsgroups = []\n",
        "newsgroups_two_newsgroups = []\n",
        "\n",
        "for i in range(len(texts)):\n",
        "    if newsgroups[i] == newsgroup_1 or newsgroups[i] == newsgroup_2:\n",
        "        texts_two_newsgroups.append(texts[i])\n",
        "        newsgroups_two_newsgroups.append(newsgroups[i])\n",
        "\n",
        "print(f\"Loaded {len(texts_two_newsgroups)} documents for {newsgroup_1} and {newsgroup_2}.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 2000 documents for sci.space and rec.autos.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bca0b60",
        "outputId": "78d26eed-b7da-47c8-88a2-951e69b52a4a"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train_initial, X_test, y_train_initial, y_test = train_test_split(\n",
        "    texts_two_newsgroups, newsgroups_two_newsgroups, test_size=0.1, stratify=newsgroups_two_newsgroups, random_state=42\n",
        ")\n",
        "\n",
        "X_train_labeled, X_train_unlabeled, y_train_labeled, y_train_unlabeled = train_test_split(\n",
        "    X_train_initial, y_train_initial, test_size=0.75, stratify=y_train_initial, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Initial training set size: {len(X_train_initial)}\")\n",
        "print(f\"Test set size: {len(X_test)}\")\n",
        "print(f\"Labeled training set size: {len(X_train_labeled)}\")\n",
        "print(f\"Unlabeled training set size: {len(X_train_unlabeled)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial training set size: 1800\n",
            "Test set size: 200\n",
            "Labeled training set size: 450\n",
            "Unlabeled training set size: 1350\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84ab9901",
        "outputId": "2c14535b-50bf-429d-995f-2d8f4192bd68"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "X_train_labeled_tfidf = vectorizer.fit_transform(X_train_labeled)\n",
        "X_train_unlabeled_tfidf = vectorizer.transform(X_train_unlabeled)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "print(f\"Shape of Labeled Training TF-IDF matrix: {X_train_labeled_tfidf.shape}\")\n",
        "print(f\"Shape of Unlabeled Training TF-IDF matrix: {X_train_unlabeled_tfidf.shape}\")\n",
        "print(f\"Shape of Test TF-IDF matrix: {X_test_tfidf.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of Labeled Training TF-IDF matrix: (450, 15544)\n",
            "Shape of Unlabeled Training TF-IDF matrix: (1350, 15544)\n",
            "Shape of Test TF-IDF matrix: (200, 15544)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vi_JVXGZAX7K",
        "outputId": "6e3f1aea-4c0e-40ad-90d6-3b0fbb77d471"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.semi_supervised import LabelSpreading\n",
        "import numpy as np\n",
        "\n",
        "lr_model = LogisticRegression(max_iter=1000)\n",
        "\n",
        "label_spreading_model = LabelSpreading(kernel='rbf', gamma=0.5)\n",
        "\n",
        "X_train_combined_tfidf = np.vstack((X_train_labeled_tfidf.toarray(), X_train_unlabeled_tfidf.toarray()))\n",
        "\n",
        "y_train_semi_supervised = np.concatenate((y_train_labeled, np.full(len(y_train_unlabeled), -1)))\n",
        "\n",
        "unique_labels = np.unique(y_train_labeled)\n",
        "label_mapping = {label: i for i, label in enumerate(unique_labels)}\n",
        "y_train_semi_supervised_numeric = np.array([label_mapping.get(label, -1) for label in y_train_semi_supervised])\n",
        "\n",
        "\n",
        "label_spreading_model.fit(X_train_combined_tfidf, y_train_semi_supervised_numeric)\n",
        "\n",
        "predicted_labels_numeric = label_spreading_model.predict(X_train_combined_tfidf)\n",
        "\n",
        "inverse_label_mapping = {i: label for label, i in label_mapping.items()}\n",
        "predicted_labels = np.array([inverse_label_mapping[label] if label in inverse_label_mapping else 'unknown' for label in predicted_labels_numeric])\n",
        "\n",
        "\n",
        "predicted_unlabeled_labels = predicted_labels[len(y_train_labeled):]\n",
        "\n",
        "X_train_final = np.vstack((X_train_labeled_tfidf.toarray(), X_train_unlabeled_tfidf.toarray()))\n",
        "y_train_final = np.concatenate((y_train_labeled, predicted_unlabeled_labels))\n",
        "\n",
        "lr_model.fit(X_train_final, y_train_final)\n",
        "\n",
        "print(\"Semi-supervised model trained.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Semi-supervised model trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "715f81a5",
        "outputId": "96d5836d-8429-4608-a6ac-892ac89de565"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "y_pred = lr_model.predict(X_test_tfidf.toarray())\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6000\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   rec.autos       1.00      0.20      0.33       100\n",
            "   sci.space       0.56      1.00      0.71       100\n",
            "\n",
            "    accuracy                           0.60       200\n",
            "   macro avg       0.78      0.60      0.52       200\n",
            "weighted avg       0.78      0.60      0.52       200\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 20  80]\n",
            " [  0 100]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3592f9cc",
        "outputId": "a618fa01-18ae-464a-8bc2-2ad28e65a62d"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "nb_model = MultinomialNB()\n",
        "\n",
        "nb_model.fit(X_train_labeled_tfidf, y_train_labeled)\n",
        "\n",
        "print(\"Naive Bayes model trained on labeled data.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes model trained on labeled data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae012a04",
        "outputId": "34f80d80-f592-42e9-bbe7-29c178510762"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "y_pred_lr = lr_model.predict(X_test_tfidf.toarray())\n",
        "\n",
        "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
        "print(f\"Logistic Regression Accuracy: {accuracy_lr:.4f}\")\n",
        "\n",
        "print(\"\\nLogistic Regression Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_lr))\n",
        "\n",
        "y_pred_nb = nb_model.predict(X_test_tfidf)\n",
        "\n",
        "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
        "print(f\"Naive Bayes Accuracy: {accuracy_nb:.4f}\")\n",
        "\n",
        "print(\"\\nNaive Bayes Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_nb))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Accuracy: 0.6000\n",
            "\n",
            "Logistic Regression Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   rec.autos       1.00      0.20      0.33       100\n",
            "   sci.space       0.56      1.00      0.71       100\n",
            "\n",
            "    accuracy                           0.60       200\n",
            "   macro avg       0.78      0.60      0.52       200\n",
            "weighted avg       0.78      0.60      0.52       200\n",
            "\n",
            "Naive Bayes Accuracy: 0.9850\n",
            "\n",
            "Naive Bayes Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   rec.autos       1.00      0.97      0.98       100\n",
            "   sci.space       0.97      1.00      0.99       100\n",
            "\n",
            "    accuracy                           0.98       200\n",
            "   macro avg       0.99      0.98      0.98       200\n",
            "weighted avg       0.99      0.98      0.98       200\n",
            "\n"
          ]
        }
      ]
    }
  ]
}