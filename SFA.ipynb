{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NptSU3NrCZd1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXM8aAVc89fe"
      },
      "source": [
        "new code\n",
        "29"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "942ccfc7",
        "outputId": "f6c819ea-97e0-407e-f8b6-c190f53814eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading dataset from https://www.cs.jhu.edu/~mdredze/datasets/sentiment/processed_acl.tar.gz...\n",
            "Download complete.\n",
            "Extracting dataset to processed_acl...\n",
            "Extraction complete.\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import tarfile\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from scipy.sparse import csr_matrix, vstack\n",
        "from scipy.linalg import sqrtm\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "url = \"https://www.cs.jhu.edu/~mdredze/datasets/sentiment/processed_acl.tar.gz\"\n",
        "dataset_path = \"processed_acl.tar.gz\"\n",
        "extracted_path = \"processed_acl\"\n",
        "\n",
        "print(f\"Downloading dataset from {url}...\")\n",
        "response = requests.get(url, stream=True)\n",
        "response.raise_for_status() # Raise an HTTPError for bad responses (4xx or 5xx)\n",
        "with open(dataset_path, 'wb') as f:\n",
        "    for chunk in response.iter_content(chunk_size=8192):\n",
        "        f.write(chunk)\n",
        "print(\"Download complete.\")\n",
        "\n",
        "print(f\"Extracting dataset to {extracted_path}...\")\n",
        "with tarfile.open(dataset_path, 'r:gz') as tar:\n",
        "    # Add filter='data' to mitigate the DeprecationWarning and improve security\n",
        "    tar.extractall(path=\".\", filter='data')\n",
        "print(\"Extraction complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8e672bd",
        "outputId": "e9316960-1c9b-4102-d2fc-67a65deab3f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Read 2000 labeled reviews from the source domain (books).\n",
            "Read 7945 all reviews from the target domain (kitchen).\n",
            "Created a labeled target test set of size 400.\n",
            "Using 1600 reviews as unlabeled data for the target domain.\n"
          ]
        }
      ],
      "source": [
        "def read_reviews(directory):\n",
        "    all_reviews_content = []\n",
        "    for sentiment in ['positive', 'negative', 'unlabeled']:\n",
        "        file_path = os.path.join(directory, f'{sentiment}.review')\n",
        "        if os.path.exists(file_path):\n",
        "            with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                lines = f.readlines()\n",
        "                all_reviews_content.extend([line.strip() for line in lines])\n",
        "    return all_reviews_content\n",
        "\n",
        "def read_labeled_reviews(directory):\n",
        "    reviews = []\n",
        "    labels = []\n",
        "    for sentiment, label in [('positive', 1), ('negative', -1)]:\n",
        "        file_path = os.path.join(directory, f'{sentiment}.review')\n",
        "        if os.path.exists(file_path):\n",
        "            with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                lines = f.readlines()\n",
        "                reviews.extend(lines)\n",
        "                labels.extend([label] * len(lines))\n",
        "    return reviews, labels\n",
        "\n",
        "source_domain = 'books'\n",
        "target_domain = 'kitchen'\n",
        "\n",
        "source_reviews, source_labels = read_labeled_reviews(os.path.join(extracted_path, source_domain))\n",
        "\n",
        "all_target_reviews = read_reviews(os.path.join(extracted_path, target_domain))\n",
        "\n",
        "labeled_target_reviews, labeled_target_labels = read_labeled_reviews(os.path.join(extracted_path, target_domain))\n",
        "\n",
        "target_unlabeled_reviews_labeled_part, target_test_reviews, target_unlabeled_labels_part, target_test_labels = train_test_split(\n",
        "    labeled_target_reviews, labeled_target_labels, test_size=400, stratify=labeled_target_labels, random_state=42)\n",
        "\n",
        "target_unlabeled_reviews_from_file = read_reviews(os.path.join(extracted_path, target_domain, 'unlabeled.review'))\n",
        "target_unlabeled_reviews = target_unlabeled_reviews_from_file + target_unlabeled_reviews_labeled_part\n",
        "\n",
        "\n",
        "print(f\"\\nRead {len(source_reviews)} labeled reviews from the source domain ({source_domain}).\")\n",
        "print(f\"Read {len(all_target_reviews)} all reviews from the target domain ({target_domain}).\")\n",
        "print(f\"Created a labeled target test set of size {len(target_test_reviews)}.\")\n",
        "print(f\"Using {len(target_unlabeled_reviews)} reviews as unlabeled data for the target domain.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afb2d2df",
        "outputId": "e499cabc-5594-4782-e972-4f8a2c82ac65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "TF-IDF feature extraction complete.\n",
            "Source features shape: (2000, 5000)\n",
            "Target unlabeled features shape: (1600, 5000)\n"
          ]
        }
      ],
      "source": [
        "all_reviews = source_reviews + target_unlabeled_reviews\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
        "\n",
        "tfidf_features = tfidf_vectorizer.fit_transform(all_reviews)\n",
        "\n",
        "source_features = tfidf_features[:len(source_reviews)]\n",
        "target_unlabeled_features = tfidf_features[len(source_reviews):]\n",
        "\n",
        "print(\"\\nTF-IDF feature extraction complete.\")\n",
        "print(f\"Source features shape: {source_features.shape}\")\n",
        "print(f\"Target unlabeled features shape: {target_unlabeled_features.shape}\")\n",
        "\n",
        "feature_names = tfidf_vectorizer.get_feature_names_out()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "446f549a",
        "outputId": "8d0fdea0-1603-485c-d871-d6c610d21fb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Identified 1832 domain-independent features.\n",
            "Identified 3168 domain-specific features.\n"
          ]
        }
      ],
      "source": [
        "source_features_dense = source_features.todense()\n",
        "target_unlabeled_features_dense = target_unlabeled_features.todense()\n",
        "\n",
        "source_word_counts = np.sum(source_features_dense > 0, axis=0)\n",
        "target_word_counts = np.sum(target_unlabeled_features_dense > 0, axis=0)\n",
        "\n",
        "source_word_counts = np.asarray(source_word_counts)[0]\n",
        "target_word_counts = np.asarray(target_word_counts)[0]\n",
        "\n",
        "min_freq = 10\n",
        "\n",
        "domain_independent_indices = [i for i, name in enumerate(feature_names)\n",
        "                              if source_word_counts[i] >= min_freq and target_word_counts[i] >= min_freq]\n",
        "\n",
        "domain_independent_features = [feature_names[i] for i in domain_independent_indices]\n",
        "domain_specific_features = [feature_names[i] for i in range(len(feature_names)) if i not in domain_independent_indices]\n",
        "\n",
        "print(f\"\\nIdentified {len(domain_independent_features)} domain-independent features.\")\n",
        "print(f\"Identified {len(domain_specific_features)} domain-specific features.\")\n",
        "\n",
        "domain_independent_indices_set = set(domain_independent_indices)\n",
        "domain_specific_indices_all = [i for i in range(len(feature_names)) if i not in domain_independent_indices_set]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c2ae4ea",
        "outputId": "5dfb0e46-4fa8-4f22-9c91-a1edcd4dca39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Running Spectral Feature Alignment (SFA) ---\n",
            "Co-occurrence matrix M constructed.\n",
            "Shape of M: (3168, 1832)\n",
            "Matrix L constructed.\n",
            "Shape of L: (5000, 5000)\n",
            "Selected 100 largest eigenvectors.\n",
            "Shape of U: (5000, 100)\n",
            "Shape of U_ds (for domain-specific features): (3168, 100)\n",
            "Applied SFA mapping to domain-specific features.\n",
            "Shape of source_ds_aligned: (2000, 100)\n",
            "Shape of target_unlabeled_ds_aligned: (1600, 100)\n",
            "Augmented features for SFA.\n",
            "Shape of source_features_augmented: (2000, 5100)\n",
            "Shape of target_unlabeled_features_augmented: (1600, 5100)\n",
            "\n",
            "Logistic Regression classifier trained on augmented source features.\n",
            "\n",
            "Predictions made on augmented target test features.\n",
            "Accuracy on target test set (SFA): 0.9525\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n--- Running Spectral Feature Alignment (SFA) ---\")\n",
        "\n",
        "M = np.zeros((len(domain_specific_features), len(domain_independent_features)))\n",
        "\n",
        "ds_feature_to_m_row_index = {name: i for i, name in enumerate(domain_specific_features)}\n",
        "di_feature_to_m_col_index = {name: i for i, name in enumerate(domain_independent_features)}\n",
        "\n",
        "all_reviews_content = read_reviews(os.path.join(extracted_path, source_domain)) + read_reviews(os.path.join(extracted_path, target_domain))\n",
        "\n",
        "for review in all_reviews_content:\n",
        "    word_counts = {}\n",
        "    for item in review.split():\n",
        "        if ':' in item:\n",
        "            word, count_str = item.split(':')\n",
        "            try:\n",
        "                word_counts[word] = int(count_str)\n",
        "            except ValueError:\n",
        "                continue\n",
        "\n",
        "    present_ds_features = [word for word in word_counts if word in ds_feature_to_m_row_index]\n",
        "    present_di_features = [word for word in word_counts if word in di_feature_to_m_col_index]\n",
        "\n",
        "    for ds_word in present_ds_features:\n",
        "        for di_word in present_di_features:\n",
        "            row_idx = ds_feature_to_m_row_index[ds_word]\n",
        "            col_idx = di_feature_to_m_col_index[di_word]\n",
        "            M[row_idx, col_idx] += 1\n",
        "\n",
        "print(\"Co-occurrence matrix M constructed.\")\n",
        "print(f\"Shape of M: {M.shape}\")\n",
        "\n",
        "A = np.block([\n",
        "    [np.zeros((M.shape[0], M.shape[0])), M],\n",
        "    [M.T, np.zeros((M.shape[1], M.shape[1]))]\n",
        "])\n",
        "\n",
        "D = np.diag(np.sum(A, axis=1))\n",
        "\n",
        "D_inv_sqrt = np.zeros_like(D)\n",
        "diagonal_sum = np.sum(A, axis=1)\n",
        "non_zero_mask = diagonal_sum > 0\n",
        "D_inv_sqrt[np.arange(D_inv_sqrt.shape[0]), np.arange(D_inv_sqrt.shape[1])][non_zero_mask] = 1.0 / np.sqrt(diagonal_sum[non_zero_mask])\n",
        "\n",
        "L = D_inv_sqrt @ A @ D_inv_sqrt\n",
        "\n",
        "print(\"Matrix L constructed.\")\n",
        "print(f\"Shape of L: {L.shape}\")\n",
        "\n",
        "# Update K for SFA\n",
        "K = 100\n",
        "\n",
        "eigenvalues, eigenvectors = np.linalg.eigh(L)\n",
        "\n",
        "sorted_indices = np.argsort(eigenvalues)[::-1]\n",
        "sorted_eigenvectors = eigenvectors[:, sorted_indices]\n",
        "\n",
        "U = sorted_eigenvectors[:, :K]\n",
        "\n",
        "print(f\"Selected {K} largest eigenvectors.\")\n",
        "print(f\"Shape of U: {U.shape}\")\n",
        "\n",
        "U_ds = U[:len(domain_specific_features), :]\n",
        "\n",
        "print(f\"Shape of U_ds (for domain-specific features): {U_ds.shape}\")\n",
        "\n",
        "source_ds_features = source_features[:, domain_specific_indices_all].todense()\n",
        "target_unlabeled_ds_features = target_unlabeled_features[:, domain_specific_indices_all].todense()\n",
        "\n",
        "source_ds_aligned = np.dot(source_ds_features, U_ds)\n",
        "target_unlabeled_ds_aligned = np.dot(target_unlabeled_ds_features, U_ds)\n",
        "\n",
        "print(\"Applied SFA mapping to domain-specific features.\")\n",
        "print(f\"Shape of source_ds_aligned: {source_ds_aligned.shape}\")\n",
        "print(f\"Shape of target_unlabeled_ds_aligned: {target_unlabeled_ds_aligned.shape}\")\n",
        "\n",
        "# Update gamma for SFA and FALSA\n",
        "gamma = 0.6\n",
        "\n",
        "source_features_dense_original = source_features.todense()\n",
        "target_unlabeled_features_dense_original = target_unlabeled_features.todense()\n",
        "\n",
        "source_features_augmented = np.hstack((source_features_dense_original, gamma * source_ds_aligned))\n",
        "target_unlabeled_features_augmented = np.hstack((target_unlabeled_features_dense_original, gamma * target_unlabeled_ds_aligned))\n",
        "\n",
        "print(\"Augmented features for SFA.\")\n",
        "print(f\"Shape of source_features_augmented: {source_features_augmented.shape}\")\n",
        "print(f\"Shape of target_unlabeled_features_augmented: {target_unlabeled_features_augmented.shape}\")\n",
        "\n",
        "sfa_classifier = LogisticRegression(C=10000)\n",
        "sfa_classifier.fit(np.asarray(source_features_augmented), source_labels)\n",
        "\n",
        "print(\"\\nLogistic Regression classifier trained on augmented source features.\")\n",
        "\n",
        "target_test_features_tfidf = tfidf_vectorizer.transform(target_test_reviews)\n",
        "\n",
        "target_test_ds_features = target_test_features_tfidf[:, domain_specific_indices_all].todense()\n",
        "\n",
        "target_test_ds_aligned = np.dot(target_test_ds_features, U_ds)\n",
        "\n",
        "target_test_features_dense_original = target_test_features_tfidf.todense()\n",
        "target_test_features_augmented = np.hstack((target_test_features_dense_original, gamma * target_test_ds_aligned))\n",
        "\n",
        "target_test_predictions = sfa_classifier.predict(np.asarray(target_test_features_augmented))\n",
        "\n",
        "sfa_accuracy = accuracy_score(target_test_labels, target_test_predictions)\n",
        "\n",
        "print(\"\\nPredictions made on augmented target test features.\")\n",
        "print(f\"Accuracy on target test set (SFA): {sfa_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0HBEJfYmUA39",
        "outputId": "85d47080-6370-404a-818d-bbb4d41076fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Running LSA and FALSA Baselines ---\n",
            "LSA transformation complete with 100 components.\n",
            "Source features shape (LSA): (2000, 100)\n",
            "Target unlabeled features shape (LSA): (1600, 100)\n",
            "Logistic Regression classifier (LSA baseline) trained.\n",
            "\n",
            "Predictions made on LSA-transformed target test features.\n",
            "Accuracy on target test set (LSA baseline): 0.9625\n",
            "\n",
            "FALSA transformation complete for domain-specific features with 100 components.\n",
            "Source DS features shape (FALSA): (2000, 100)\n",
            "Target unlabeled DS features shape (FALSA): (1600, 100)\n",
            "Augmented features for FALSA.\n",
            "Shape of source_features_falsa_augmented: (2000, 5100)\n",
            "Shape of target_test_features_falsa_augmented: (400, 5100)\n",
            "Logistic Regression classifier (FALSA baseline) trained.\n",
            "\n",
            "Predictions made on augmented target test features using FALSA baseline.\n",
            "Accuracy on target test set (FALSA baseline): 0.9575\n"
          ]
        }
      ],
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "from scipy.sparse import vstack\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "print(\"\\n--- Running LSA and FALSA Baselines ---\")\n",
        "\n",
        "# Update n_components_lsa for LSA and FALSA\n",
        "n_components_lsa = 100\n",
        "svd = TruncatedSVD(n_components=n_components_lsa, random_state=42)\n",
        "\n",
        "tfidf_features = vstack([source_features, target_unlabeled_features])\n",
        "\n",
        "lsa_features = svd.fit_transform(tfidf_features)\n",
        "\n",
        "source_features_lsa = lsa_features[:len(source_reviews)]\n",
        "target_unlabeled_features_lsa = lsa_features[len(source_reviews):]\n",
        "\n",
        "print(f\"LSA transformation complete with {n_components_lsa} components.\")\n",
        "print(f\"Source features shape (LSA): {source_features_lsa.shape}\")\n",
        "print(f\"Target unlabeled features shape (LSA): {target_unlabeled_features_lsa.shape}\")\n",
        "\n",
        "lsa_classifier = LogisticRegression(C=10000)\n",
        "lsa_classifier.fit(source_features_lsa, source_labels)\n",
        "\n",
        "print(\"Logistic Regression classifier (LSA baseline) trained.\")\n",
        "\n",
        "target_test_features_tfidf_lsa = tfidf_vectorizer.transform(target_test_reviews)\n",
        "target_test_features_lsa = svd.transform(target_test_features_tfidf_lsa)\n",
        "\n",
        "lsa_target_test_predictions = lsa_classifier.predict(target_test_features_lsa)\n",
        "\n",
        "lsa_accuracy = accuracy_score(target_test_labels, lsa_target_test_predictions)\n",
        "\n",
        "print(\"\\nPredictions made on LSA-transformed target test features.\")\n",
        "print(f\"Accuracy on target test set (LSA baseline): {lsa_accuracy}\")\n",
        "\n",
        "source_ds_features_tfidf = source_features[:, domain_specific_indices_all]\n",
        "target_unlabeled_ds_features_tfidf = target_unlabeled_features[:, domain_specific_indices_all]\n",
        "target_test_ds_features_tfidf = target_test_features_tfidf_lsa[:, domain_specific_indices_all]\n",
        "\n",
        "all_ds_features_tfidf = vstack([source_ds_features_tfidf, target_unlabeled_ds_features_tfidf])\n",
        "svd_falsa = TruncatedSVD(n_components=n_components_lsa, random_state=42)\n",
        "falsa_ds_features = svd_falsa.fit_transform(all_ds_features_tfidf)\n",
        "\n",
        "source_ds_features_falsa = falsa_ds_features[:source_ds_features_tfidf.shape[0]]\n",
        "target_unlabeled_ds_features_falsa = falsa_ds_features[source_ds_features_tfidf.shape[0]:]\n",
        "\n",
        "print(f\"\\nFALSA transformation complete for domain-specific features with {n_components_lsa} components.\")\n",
        "print(f\"Source DS features shape (FALSA): {source_ds_features_falsa.shape}\")\n",
        "print(f\"Target unlabeled DS features shape (FALSA): {target_unlabeled_ds_features_falsa.shape}\")\n",
        "\n",
        "source_features_falsa_augmented = np.hstack((source_features.todense(), gamma * source_ds_features_falsa))\n",
        "target_test_features_falsa_augmented = np.hstack((target_test_features_tfidf_lsa.todense(), gamma * svd_falsa.transform(target_test_ds_features_tfidf)))\n",
        "\n",
        "print(\"Augmented features for FALSA.\")\n",
        "print(f\"Shape of source_features_falsa_augmented: {source_features_falsa_augmented.shape}\")\n",
        "print(f\"Shape of target_test_features_falsa_augmented: {target_test_features_falsa_augmented.shape}\")\n",
        "\n",
        "falsa_classifier = LogisticRegression(C=10000)\n",
        "falsa_classifier.fit(np.asarray(source_features_falsa_augmented), source_labels)\n",
        "\n",
        "print(\"Logistic Regression classifier (FALSA baseline) trained.\")\n",
        "\n",
        "falsa_target_test_predictions = falsa_classifier.predict(np.asarray(target_test_features_falsa_augmented))\n",
        "\n",
        "falsa_accuracy = accuracy_score(target_test_labels, falsa_target_test_predictions)\n",
        "\n",
        "print(\"\\nPredictions made on augmented target test features using FALSA baseline.\")\n",
        "print(f\"Accuracy on target test set (FALSA baseline): {falsa_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4a39589b",
        "outputId": "be9238fc-650f-4d24-d0e8-492963998a80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Running SCL Baseline ---\n",
            "Identified 358 pivot features.\n",
            "Identified 4642 non-pivot features.\n",
            "Source pivot features shape: (2000, 358)\n",
            "Source non-pivot features shape: (2000, 4642)\n",
            "Target unlabeled pivot features shape: (1600, 358)\n",
            "Target unlabeled non-pivot features shape: (1600, 4642)\n",
            "\n",
            "Training linear classifiers for non-pivot features...\n",
            "Using 50 non-pivot features for SCL transformation (top 50 based on correlation).\n",
            "Trained classifier for 10/50 selected non-pivot features.\n",
            "Trained classifier for 20/50 selected non-pivot features.\n",
            "Trained classifier for 30/50 selected non-pivot features.\n",
            "Trained classifier for 40/50 selected non-pivot features.\n",
            "Trained classifier for 50/50 selected non-pivot features.\n",
            "Finished training classifiers for selected non-pivot features.\n",
            "\n",
            "Transformation matrix P constructed with shape: (358, 50)\n",
            "Applied SCL transformation to non-pivot features.\n",
            "Shape of source_transformed_non_pivot: (2000, 50)\n",
            "Shape of target_unlabeled_transformed_non_pivot: (1600, 50)\n",
            "Shape of target_test_transformed_non_pivot: (400, 50)\n",
            "Augmented features for SCL.\n",
            "Shape of source_features_scl_augmented: (2000, 5050)\n",
            "Shape of target_test_features_scl_augmented: (400, 5050)\n",
            "\n",
            "Logistic Regression classifier (SCL baseline) trained on augmented source features.\n",
            "\n",
            "Predictions made on augmented target test features using SCL baseline.\n",
            "Accuracy on target test set (SCL baseline): 0.9775\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from scipy.sparse import hstack, csr_matrix\n",
        "import numpy as np\n",
        "\n",
        "print(\"\\n--- Running SCL Baseline ---\")\n",
        "\n",
        "source_labels_np = np.array(source_labels)\n",
        "\n",
        "correlations = []\n",
        "for i in range(source_features_dense.shape[1]):\n",
        "    feature_vector = np.asarray(source_features_dense[:, i]).flatten()\n",
        "    if np.std(feature_vector) > 1e-6:\n",
        "        correlation = np.corrcoef(feature_vector, source_labels_np)[0, 1]\n",
        "        correlations.append(abs(correlation))\n",
        "    else:\n",
        "        correlations.append(0)\n",
        "\n",
        "correlations = np.array(correlations)\n",
        "\n",
        "min_freq_pivot = 10\n",
        "min_correlation = 0.05\n",
        "\n",
        "# Update num_pivots for SCL\n",
        "num_pivots = 500\n",
        "\n",
        "pivot_indices = [i for i, name in enumerate(feature_names)\n",
        "                 if source_word_counts[i] >= min_freq_pivot and\n",
        "                    target_word_counts[i] >= min_freq_pivot and\n",
        "                    correlations[i] >= min_correlation]\n",
        "\n",
        "# Select the top 'num_pivots' based on correlation\n",
        "sorted_indices_by_correlation = np.argsort(correlations[pivot_indices])[::-1]\n",
        "top_pivot_indices = [pivot_indices[i] for i in sorted_indices_by_correlation[:num_pivots]]\n",
        "\n",
        "pivot_features = [feature_names[i] for i in top_pivot_indices]\n",
        "non_pivot_indices = [i for i in range(len(feature_names)) if i not in top_pivot_indices]\n",
        "non_pivot_features = [feature_names[i] for i in non_pivot_indices]\n",
        "\n",
        "\n",
        "print(f\"Identified {len(pivot_features)} pivot features.\")\n",
        "print(f\"Identified {len(non_pivot_features)} non-pivot features.\")\n",
        "\n",
        "source_pivot_features = source_features[:, top_pivot_indices]\n",
        "source_non_pivot_features = source_features[:, non_pivot_indices]\n",
        "target_unlabeled_pivot_features = target_unlabeled_features[:, top_pivot_indices]\n",
        "target_unlabeled_non_pivot_features = target_unlabeled_features[:, non_pivot_indices]\n",
        "\n",
        "print(f\"Source pivot features shape: {source_pivot_features.shape}\")\n",
        "print(f\"Source non-pivot features shape: {source_non_pivot_features.shape}\")\n",
        "print(f\"Target unlabeled pivot features shape: {target_unlabeled_pivot_features.shape}\")\n",
        "print(f\"Target unlabeled non-pivot features shape: {target_unlabeled_non_pivot_features.shape}\")\n",
        "\n",
        "all_pivot_features = vstack([source_pivot_features, target_unlabeled_pivot_features])\n",
        "\n",
        "P_columns = []\n",
        "\n",
        "print(\"\\nTraining linear classifiers for non-pivot features...\")\n",
        "all_reviews_features = vstack([source_features, target_unlabeled_features])\n",
        "\n",
        "# Update h for SCL\n",
        "h = 50\n",
        "\n",
        "# Instead of training a classifier for each non-pivot feature, we will use the top h non-pivot features based on correlation.\n",
        "# This is a simplification of the original SCL but allows for a more manageable computation.\n",
        "# Select top h non-pivot features based on correlation\n",
        "non_pivot_correlations = correlations[non_pivot_indices]\n",
        "sorted_non_pivot_indices_by_correlation = np.argsort(non_pivot_correlations)[::-1]\n",
        "top_non_pivot_indices = [non_pivot_indices[i] for i in sorted_non_pivot_indices_by_correlation[:h]]\n",
        "\n",
        "# Re-calculate non-pivot features based on the top h\n",
        "non_pivot_indices = top_non_pivot_indices\n",
        "non_pivot_features = [feature_names[i] for i in non_pivot_indices]\n",
        "\n",
        "print(f\"Using {len(non_pivot_features)} non-pivot features for SCL transformation (top {h} based on correlation).\")\n",
        "\n",
        "\n",
        "source_non_pivot_features = source_features[:, non_pivot_indices]\n",
        "target_unlabeled_non_pivot_features = target_unlabeled_features[:, non_pivot_indices]\n",
        "\n",
        "all_pivot_features = vstack([source_pivot_features, target_unlabeled_pivot_features])\n",
        "\n",
        "# Now train classifiers for the selected non-pivot features\n",
        "P_columns = []\n",
        "for i, non_pivot_idx in enumerate(non_pivot_indices):\n",
        "    non_pivot_target = np.asarray(all_reviews_features[:, non_pivot_idx].todense()).flatten() > 0\n",
        "\n",
        "    correspondence_classifier = LogisticRegression(C=1.0, solver='liblinear')\n",
        "    correspondence_classifier.fit(all_pivot_features, non_pivot_target)\n",
        "\n",
        "    P_columns.append(correspondence_classifier.coef_[0])\n",
        "\n",
        "    if (i + 1) % 10 == 0: # Adjusted print frequency for smaller h\n",
        "        print(f\"Trained classifier for {i + 1}/{len(non_pivot_indices)} selected non-pivot features.\")\n",
        "\n",
        "print(\"Finished training classifiers for selected non-pivot features.\")\n",
        "\n",
        "\n",
        "P = np.array(P_columns).T\n",
        "\n",
        "\n",
        "print(f\"\\nTransformation matrix P constructed with shape: {P.shape}\")\n",
        "\n",
        "target_test_features_tfidf_scl = tfidf_vectorizer.transform(target_test_reviews)\n",
        "\n",
        "target_test_pivot_features = target_test_features_tfidf_scl[:, top_pivot_indices]\n",
        "target_test_non_pivot_features = target_test_features_tfidf_scl[:, non_pivot_indices]\n",
        "\n",
        "\n",
        "source_transformed_non_pivot = source_pivot_features.dot(P)\n",
        "\n",
        "target_unlabeled_transformed_non_pivot = target_unlabeled_pivot_features.dot(P)\n",
        "\n",
        "target_test_transformed_non_pivot = target_test_pivot_features.dot(P)\n",
        "\n",
        "print(\"Applied SCL transformation to non-pivot features.\")\n",
        "print(f\"Shape of source_transformed_non_pivot: {source_transformed_non_pivot.shape}\")\n",
        "print(f\"Shape of target_unlabeled_transformed_non_pivot: {target_unlabeled_transformed_non_pivot.shape}\")\n",
        "print(f\"Shape of target_test_transformed_non_pivot: {target_test_transformed_non_pivot.shape}\")\n",
        "\n",
        "source_features_dense_original_scl = source_features.todense()\n",
        "target_test_features_dense_original_scl = target_test_features_tfidf_scl.todense()\n",
        "\n",
        "source_features_scl_augmented = np.hstack((source_features_dense_original_scl, source_transformed_non_pivot))\n",
        "target_test_features_scl_augmented = np.hstack((target_test_features_dense_original_scl, target_test_transformed_non_pivot))\n",
        "\n",
        "\n",
        "print(\"Augmented features for SCL.\")\n",
        "print(f\"Shape of source_features_scl_augmented: {source_features_scl_augmented.shape}\")\n",
        "print(f\"Shape of target_test_features_scl_augmented: {target_test_features_scl_augmented.shape}\")\n",
        "\n",
        "scl_classifier = LogisticRegression(C=10000)\n",
        "scl_classifier.fit(np.asarray(source_features_scl_augmented), source_labels)\n",
        "\n",
        "print(\"\\nLogistic Regression classifier (SCL baseline) trained on augmented source features.\")\n",
        "\n",
        "scl_target_test_predictions = scl_classifier.predict(np.asarray(target_test_features_scl_augmented))\n",
        "\n",
        "scl_accuracy = accuracy_score(target_test_labels, scl_target_test_predictions)\n",
        "\n",
        "print(\"\\nPredictions made on augmented target test features using SCL baseline.\")\n",
        "print(f\"Accuracy on target test set (SCL baseline): {scl_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9b11f68e",
        "outputId": "8b314550-d013-49b5-d2f6-619218207f19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Running NoTransf Baseline ---\n",
            "Logistic Regression classifier (NoTransf baseline) trained on original source features.\n",
            "Predictions made on original target test features using NoTransf baseline.\n",
            "Accuracy on target test set (NoTransf baseline): 0.9525\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n--- Running NoTransf Baseline ---\")\n",
        "\n",
        "no_transf_classifier = LogisticRegression(C=10000)\n",
        "no_transf_classifier.fit(np.asarray(source_features.todense()), source_labels)\n",
        "\n",
        "print(\"Logistic Regression classifier (NoTransf baseline) trained on original source features.\")\n",
        "\n",
        "target_test_features_original = tfidf_vectorizer.transform(target_test_reviews)\n",
        "\n",
        "no_transf_target_test_predictions = no_transf_classifier.predict(np.asarray(target_test_features_original.todense()))\n",
        "\n",
        "no_transf_accuracy = accuracy_score(target_test_labels, no_transf_target_test_predictions)\n",
        "\n",
        "print(\"Predictions made on original target test features using NoTransf baseline.\")\n",
        "print(f\"Accuracy on target test set (NoTransf baseline): {no_transf_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3396f096",
        "outputId": "9c556efd-8935-4c8c-eb92-bdb6ba44d47b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading dataset from https://www.cs.jhu.edu/~mdredze/datasets/sentiment/processed_acl.tar.gz...\n",
            "Download complete.\n",
            "Extracting dataset to processed_acl...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-1333863702.py:27: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
            "  tar.extractall(path=\".\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extraction complete.\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import tarfile\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from scipy.sparse import csr_matrix, vstack\n",
        "from scipy.linalg import sqrtm\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "url = \"https://www.cs.jhu.edu/~mdredze/datasets/sentiment/processed_acl.tar.gz\"\n",
        "dataset_path = \"processed_acl.tar.gz\"\n",
        "extracted_path = \"processed_acl\"\n",
        "\n",
        "print(f\"Downloading dataset from {url}...\")\n",
        "response = requests.get(url, stream=True)\n",
        "with open(dataset_path, 'wb') as f:\n",
        "    for chunk in response.iter_content(chunk_size=8192):\n",
        "        f.write(chunk)\n",
        "print(\"Download complete.\")\n",
        "\n",
        "print(f\"Extracting dataset to {extracted_path}...\")\n",
        "with tarfile.open(dataset_path, 'r:gz') as tar:\n",
        "    tar.extractall(path=\".\")\n",
        "print(\"Extraction complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "c9d1186c",
        "outputId": "71be1cb5-9407-45d7-eb8c-41d7e6753201"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Read 2000 labeled reviews from the source domain (electronics).\n",
            "Read 7945 all reviews from the target domain (kitchen).\n",
            "Created a labeled target test set of size 400.\n",
            "Using 1600 reviews as unlabeled data for the target domain.\n"
          ]
        }
      ],
      "source": [
        "def read_reviews(directory):\n",
        "    all_reviews_content = []\n",
        "    for sentiment in ['positive', 'negative', 'unlabeled']:\n",
        "        file_path = os.path.join(directory, f'{sentiment}.review')\n",
        "        if os.path.exists(file_path):\n",
        "            with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                lines = f.readlines()\n",
        "                all_reviews_content.extend([line.strip() for line in lines])\n",
        "    return all_reviews_content\n",
        "\n",
        "def read_labeled_reviews(directory):\n",
        "    reviews = []\n",
        "    labels = []\n",
        "    for sentiment, label in [('positive', 1), ('negative', -1)]:\n",
        "        file_path = os.path.join(directory, f'{sentiment}.review')\n",
        "        if os.path.exists(file_path):\n",
        "            with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                lines = f.readlines()\n",
        "                reviews.extend(lines)\n",
        "                labels.extend([label] * len(lines))\n",
        "    return reviews, labels\n",
        "\n",
        "source_domain = 'electronics'\n",
        "target_domain = 'kitchen'\n",
        "\n",
        "source_reviews, source_labels = read_labeled_reviews(os.path.join(extracted_path, source_domain))\n",
        "\n",
        "all_target_reviews = read_reviews(os.path.join(extracted_path, target_domain))\n",
        "\n",
        "labeled_target_reviews, labeled_target_labels = read_labeled_reviews(os.path.join(extracted_path, target_domain))\n",
        "\n",
        "target_unlabeled_reviews_labeled_part, target_test_reviews, target_unlabeled_labels_part, target_test_labels = train_test_split(\n",
        "    labeled_target_reviews, labeled_target_labels, test_size=400, stratify=labeled_target_labels, random_state=42)\n",
        "\n",
        "target_unlabeled_reviews_from_file = read_reviews(os.path.join(extracted_path, target_domain, 'unlabeled.review'))\n",
        "target_unlabeled_reviews = target_unlabeled_reviews_from_file + target_unlabeled_reviews_labeled_part\n",
        "\n",
        "print(f\"\\nRead {len(source_reviews)} labeled reviews from the source domain ({source_domain}).\")\n",
        "print(f\"Read {len(all_target_reviews)} all reviews from the target domain ({target_domain}).\")\n",
        "print(f\"Created a labeled target test set of size {len(target_test_reviews)}.\")\n",
        "print(f\"Using {len(target_unlabeled_reviews)} reviews as unlabeled data for the target domain.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fc90df94",
        "outputId": "40a777a4-6c9a-4bd4-f728-382339aaaf21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Results ---\n",
            "SFA Accuracy: 0.9525\n",
            "NoTransf Baseline Accuracy: 0.9525\n",
            "LSA Baseline Accuracy: 0.9625\n",
            "FALSA Baseline Accuracy: 0.9575\n",
            "SCL Baseline Accuracy: 0.9775\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(\"\\n--- Results ---\")\n",
        "print(f\"SFA Accuracy: {sfa_accuracy}\")\n",
        "print(f\"NoTransf Baseline Accuracy: {no_transf_accuracy}\")\n",
        "print(f\"LSA Baseline Accuracy: {lsa_accuracy}\")\n",
        "print(f\"FALSA Baseline Accuracy: {falsa_accuracy}\")\n",
        "print(f\"SCL Baseline Accuracy: {scl_accuracy}\")\n",
        "\n",
        "labels = ['SFA', 'NoTransf', 'LSA', 'FALSA', 'SCL']\n",
        "accuracies = [sfa_accuracy, no_transf_accuracy, lsa_accuracy, falsa_accuracy, scl_accuracy]\n",
        "\n",
        "x = np.arange(len(labels))\n",
        "width = 0.35\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "rects = ax.bar(x, accuracies, width, label='Accuracy')\n",
        "\n",
        "ax.set_ylabel('Accuracy')\n",
        "ax.set_title('Comparison of Model Accuracies on Target Domain Test Set')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(labels)\n",
        "ax.set_ylim([0, 1.1])\n",
        "\n",
        "def autolabel(rects):\n",
        "    for rect in rects:\n",
        "        height = rect.get_height()\n",
        "        ax.annotate(f'{height:.4f}',\n",
        "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
        "                    xytext=(0, 3),\n",
        "                    textcoords=\"offset points\",\n",
        "                    ha='center', va='bottom')\n",
        "\n",
        "autolabel(rects)\n",
        "\n",
        "fig.tight_layout()\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}